Content
=======


Section 6: Terraform Concepts - Building Blocks
25. Provision Software with Terraform
26. Lab : Provision Software with Terraform
27. DataSource in Terraform
28. Lab : DataSource in Terraform
29. Lab 2 : DataSource in Terraform
30. Output Attribute in TF
31. Lab : Output Attribute in TF
32. Remote State in Terraform
33. Lab : Remote State in Terraform



25. Provision Software with Terraform
=====================================

There are 2 ways to Provision Software on your Instance.

1st way - Build Custom AMI (Amazon Machine Image): - PREFFERABLE
--------------------------------------------------
	➢ Bundle your softwares and Files in Base Image.

	➢ Packer is Tool to Bundle the Custom AMIs.
		- Packer and Chef can help us create custom AIMs (with additional tools that we need for our specific stack)


2nd way - Boot Standard AMIs (Amazon Machine Image) and Install Software on Instance at Runtime.
------------------------------------------------------------------------------------------------
CONS:
	- when the base OS image is updated we can have discrapencies with the installation of the tools on it
	- installation on the runtime is not preffered

	➢ Using File Upload.
		- We can create scripts and upload them on the box
	➢ Using Remote-exec
		- We can then execute them with remote-exec
	➢ Using tools like Chef, Puppet & Ansible.



➢ Chef is Integrated with Terraform.

➢ User Can Run Puppet using Remote-Exec

➢ For Ansible, First Run Terraform, Get the Host IP address and then execute Ansible Playbook on Host.



File Upload on Instance
-----------------------

We have to provide, specify the file and its destination
------------------------------------------------------
resource "aws_instance" "MyFirstInstnace" {
  ami = lookup(var.AMIS, var.AWS_REGION)
  instance_type = "t2.micro"

  tags = {
    Name = "demoinstnce"
  }

  provisioner "file" {
    source = "installNginx.sh"
    destination = "/etc/installNginx.sh"
  }
}
------------------------------------------------------


➢ Remote-exec needs to be execute to execute the Script
	- we can use python script or shell script

➢ Terraform Provisioner needs to use SSH(Unix/Linux) or WinRM(Windows Machine)


User can use Connection to Make SSH Connection on Host.
-------------------------------------------------------

We must specify the user and password for the remote connection in order to execute the scripts
------------------------------------------------------
provisioner "file" {
  source = "installNginx.sh"
  destination = "/etc/installNginx.sh"

  connection {
    user = var.instance_user
    password = var.instance_pass
  }
}
------------------------------------------------------




On AWS User needs to use SSH KeyPairs instead of Password.
----------------------------------------------------------

If we use AZURE or GCP we can use SSH connection, but if we use AWS private/public key is the preffered way.

------------------------------------------------------
resource "aws_key_pair" "levelup-key" {			// define the connection resource type and name
  key_name = "levelup_key"				// define the private key
  public_key = "ssh rsa my-public-key"			// define the public key
}

resource "aws_instance" "MyFirstInstnace" {		// define the instance provider and name
  ami = lookup(var.AMIS, var.AWS_REGION)		// define the AMI
  instance_type = "t2.micro"				// tier of the machine
  key_name = aws_key_pair.levelup_key.key_name		// link the connection credentials

  tags = {
    Name = "custom_instance"				// tag thee instance machine
  }

  provisioner "file" {					// define the script resource file 
    source = "installNginx.sh"				// specify the name of the script file
    destination = "/etc/installNginx.sh"		// specify the location of the script file

    connection {					// define the connection
      user = var.instance_user				// link user 
      private_key = file(var.path_to_private_key)	// link the private key for the user
    }
  }
}
------------------------------------------------------

This is general template (may have some small variaties) to use private/public key combination to craete the connection to AWS machine



Remote-exec need to execute the Script.
---------------------------------------

This are the provisioner commands that will be executed
------------------------------------------------------
provisioner "remote-exec" {
  inline = [					// define list of commands taht will be executed
    "chmod +x /etc/installNginx.sh",		// set rights of the script file
    "/etc/installNginx.sh"			// execute the script file
  ]
}
------------------------------------------------------

2nd way summary
- Creating the isntance
- Installing the software 
	- prepare a script
	- create the connection on the box
	- upload and execute the script




26. Lab : Provision Software with Terraform
===========================================

We have exampel files for the lab
	➢ createInstace.tf
	➢ provider.tf
	➢ variables.tf
	➢ installNginx.sh


createInstace.tf
------------------------------------------------------
resource "aws_key_pair" "levelup_key" {		# declare resource aws key pair with name to connect the aws instance
    key_name = "levelup_key"				# define the name of the public key - we can use any name
    public_key = file(var.PATH_TO_PUBLIC_KEY)		# define the path to the public key variable
}

resource "aws_instance" "MyFirstInstnace" {		# define the instance type and name
  ami           = lookup(var.AMIS, var.AWS_REGION)	# link the AMI options
  instance_type = "t2.micro"				# set machine tier
  key_name      = aws_key_pair.levelup_key.key_name	# link the key from aws_key_pair resource

  tags = {						# instance tag
    Name = "custom_instance"
  }

  provisioner "file" {					# define provisioner - file
      source = "installNginx.sh"			# define the file name
      destination = "/tmp/installNginx.sh"		# define the file location path
  }

  provisioner "remote-exec" {				# define another prvisioner for the commands
    inline = [						# commands list
      "chmod +x /tmp/installNginx.sh",			# provide executable permissions the file
      "sudo sed -i -e 's/\r$//' /tmp/installNginx.sh",  # Remove the spurious CR characters if the file is created on nodepad++
      "sudo /tmp/installNginx.sh",			# execute the script file
    ]
  }

  connection {							# define connection
    host        = coalesce(self.public_ip, self.private_ip)	# receive private and public key
    type        = "ssh"						# specify the type of the connection
    user        = var.INSTANCE_USERNAME				# link the user
    private_key = file(var.PATH_TO_PRIVATE_KEY)			# link the private key
  }
}
------------------------------------------------------



provider.tf
------------------------------------------------------
provider "aws" {
  access_key = var.AWS_ACCESS_KEY
  secret_key = var.AWS_SECRET_KEY
  region     = var.AWS_REGION
}
------------------------------------------------------



variables.tf
------------------------------------------------------
variable "AWS_ACCESS_KEY" {				// define access key variable
    type = string
    default = "xxxxxxxxxxxxxxxx"
}

variable "AWS_SECRET_KEY" {}				// define empty secret access key

variable "AWS_REGION" {					// define regions variable with default value
default = "us-east-2"
}

variable "Security_Group"{				// define security group variable with default values
    type = list
    default = ["sg-24076", "sg-90890", "sg-456789"]
}

variable "AMIS" {					// set AIM IDs by region as default options
    type = map
    default = {
        us-east-1 = "ami-0f40c8f97004632f9"
        us-east-2 = "ami-05692172625678b4e"
        us-west-2 = "ami-0352d5a37fb4f603f"
        us-west-1 = "ami-0f40c8f97004632f9"
    }
}

variable "PATH_TO_PRIVATE_KEY" {	// define variable for the AWS connection private key with default name value
  default = "levelup_key"
}

variable "PATH_TO_PUBLIC_KEY" {		// define variable for the AWS connection public key with default linked value
  default = "levelup_key.pub"		// if we have the keys in different directory, here we have to specify the full path
}

variable "INSTANCE_USERNAME" {		// define instance username with default value
  default = "ubuntu"
}
------------------------------------------------------


This is the file wew ill use to install nginx on the AWS instance

installNginx.sh
------------------------------------------------------
#!/bin/bash

# sleep until instance is ready
until [[ -f /var/lib/cloud/instance/boot-finished ]]; do
    sleep 1
done

# install nginx
apt-get update				// update package manager
apt-get -y install nginx		// install nginx

# make sure nginx is started
service nginx start

------------------------------------------------------



We must log into the work machine on DigitalOcean
	terminal --> ssh root@IP
	terminal --> yes/password


Create new directory and create the files or pull hte repo with the uploaded files
	terminal --> mkdir terrform_blocks

Navigate to the directory
	terminal --> cd terrform_blocks


Create all files with the actions below
---------------------------------------
- optional and more easy is to create a repository with the .tf files and pull the repo in the specific directory

Create the files
	terminal --> vi filename.tf

Insert the file content
	terminal --> insert		# to enter in insert mode
	terminal --> Shift + Insert	# to paste the file content with the correct indentation

Only the srcipt file should be in the root directory or the directory specified in the createInstace.tf/provisioner "file"/description


INIT
----
Initialize terraform
	terminal --> terraform init

We have to generate private and public keys
	terminal --> ssh-keygen -f levelup_key		# specify the file with the keys in it

	# We can se tsecurity phrase (optional)/enter for blank

List the files in the current direcotry
	termianl --> ls

	result: we must have levelup-key and levelup-key.pub files - the generated private and public keys

PLAN
----
Try to plan terraform resources
	terminal --> terraform plan
	terminal --> xxxxxxxxxxxxxxxxxxxxxxxxxxxxx 	# secret key

	# the plan should be successful
	# on the console we can see printed aws_key_pair public key
	

Before Applying the resources we need to modify the security group on AWS. We need to give access from our local PC.
- Login on AWS
- go to EC2/Secutiry Groups
- open the security group/inbound rules/Edit inbound rules/Add rule
	- Type: All traffic
	- Source: My IP			# this will apply the current IP that we use (local PC)
	- save rule

APPLY
-----
Apply the plan made on the DigitalOcean Ubuntu machine
	terminal --> terraform apply
	terminal --> xxxxxxxxxxxxxxxxxxxxxx		# provide the seucrity key
	terminal --> yes				# confirm


We can see the logs on the console.

Check the resource creation on AWS/EC2. Because we added a rule for our local PC we can test the enginx on AWS. 


DESTROY
-------
We can now destroy the created resources on AWS
	terminal --> terraform destroy




27. DataSource in Terraform
===========================

➢ Terraform provides DataSource for Certain Cloud Providers like AWS.

➢ DataSource Provides the dynamic Information about entities that are not managed by the current Terraform and configuration.

➢ AWS provides a lot of structured data which can be accessed via AWS APIs.

➢ Terraform expose this information using DataSources like AMIs, Availability Zones.

➢ Referencing a resource defined in a data source won’t create the resource itself, and your plan will fail if you reference nonexistent data or infrastructure.



➢ DataSource also provides the All IPs in use by AWS.

➢ This will help in IP Base Traffic filter.

➢ Traffic Filer on AWS can be done via Security Groups.

➢ Incoming and Outgoing Traffic can be done via Inbound Rules and Outbound Rules.

➢ Rules filter the traffic on the basis of Protocol, IP Range, and Ports.





28. Lab : DataSource in Terraform
=================================

We have 3 files
---------------
➢ createInstance.tf
➢ provider.tf
➢ variables.tf

We can find the correct AMI here - https://us-west-1.console.aws.amazon.com/ec2/home?region=us-west-1#AMICatalog:


createInstance.tf
------------------------------------------------------
data "aws_availability_zones" "available" {}				# fetch all AWS availabilit zones

data "aws_ami" "latest_ubuntu" {					# find AMI image
  most_recent = true
  owners      = ["099720109477"]					# official image owner

  filter {								# set filter to fetch images with names
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"] 
  }

  filter {								# set filter to fetch images with virtualization types
    name   = "virtualization-type"
    values = ["hvm"]
  }
}

resource "aws_instance" "web" {
  ami           = data.aws_ami.latest_ubuntu.id				# data AMI image with the result of the filters
  instance_type = "t2.micro"						# instance tier
  availability_zone = data.aws_availability_zones.available.names[1]	# use the availability zone us-east-2b - first line 

  tags = {
    Name = "custom_instance"
  }
}
------------------------------------------------------


provider.tf
------------------------------------------------------
provider "aws" {
  access_key = var.AWS_ACCESS_KEY
  secret_key = var.AWS_SECRET_KEY
  region     = var.AWS_REGION
}
------------------------------------------------------


variables.tf
------------------------------------------------------
variable "AWS_ACCESS_KEY" {
    type = string
    default = "xxxxxxxxxxxxxxxxxxxx"
}

variable "AWS_SECRET_KEY" {}

variable "AWS_REGION" {
default = "us-east-2"
}

variable "Security_Group"{
    type = list
    default = ["sg-24076", "sg-90890", "sg-456789"]
}

variable "AMIS" {
    type = map
    default = {
        us-west-2 = "ami-0352d5a37fb4f603f"
        us-west-1 = "ami-0f40c8f97004632f9"
    }
}
------------------------------------------------------


Login to the igitalOcean ubuntu and pull the files from github.
	terminal --> ssh root@IP
	terminal --> password

Pull the repo
	terminal --> git clone repo_url

Navigate to the teraform working derectory
	terminal --> cd terraform

Install terraform if not installed
	terminal --> wget -O - https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(grep -oP '(?<=UBUNTU_CODENAME=).*' /etc/os-release || lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update && sudo apt install terraform

If error appear execute the command
	terminal --> snap install terraform --classic

INIT
----
Initialize terrafomr
	terminal --> terraform init

PLAN
----
Plan terraform resources
	terminal --> terraform plan
	# the plan should be successful and we can review the logs

With the plan we get the aim ID and availability zone




29. Lab 2 : DataSource in Terraform
===================================
In this lab we will create dynamically security group on AWS with terraform. We will restrict the traffic to specific ports on the machine.

We have 4 files
---------------
➢ createInstance.tf
➢ provider.tf
➢ variables.tf
➢ securitygroup.tf

We have one additional file from the last lab - securitygroup.tf

securitygroup.tf
------------------------------------------------------
data "aws_ip_ranges" "us_east_ip_range" {
    regions = ["us-east-1","us-east-2"]			# set AWS regions
    services = ["ec2"]					# set AWS service
}

resource "aws_security_group" "sg-custom_us_east" {
    name = "custom_us_east"

    ingress {						# set incoming traffic configuration
        from_port = "443"				# specify start port
        to_port = "443"					# specify end port 	1 port in total
        protocol = "tcp"				# specify the protocol
        cidr_blocks = slice(data.aws_ip_ranges.us_east_ip_range.cidr_blocks, 0, 50)
    }

    tags = {
        CreateDate = data.aws_ip_ranges.us_east_ip_range.create_date	# set create date of the security group
        SyncToken = data.aws_ip_ranges.us_east_ip_range.sync_token	# set the token for the security group
    }
}
------------------------------------------------------

Login to the igitalOcean ubuntu and pull the files from github.
	terminal --> ssh root@IP
	terminal --> password

Pull the repo
	terminal --> git clone repo_url

Navigate to the teraform working derectory
	terminal --> cd terraform_work_folder

INIT
----
Initialize terrafomr
	terminal --> terraform init

PLAN
----
Plan terraform resources
	terminal --> terraform plan -var AWS_REGION="us-east-1"
	# the plan should be successful and we can review the logs
	terminal --> AWS Secret access key

The plan should be successful - we can create 2 resources
	# aws_instance.web will be created						# Instance
     		 + ami                                  = "ami-0a7d80731ae1b2435"
    		 + arn                                  = (known after apply)
    		 + associate_public_ip_address          = (known after apply)
      		 + availability_zone                    = "us-east-1b"
	...
	# aws_security_group.sg-custom_us_east will be created				# security group
	+ resource "aws_security_group" "sg-custom_us_east" {
      	+ arn                    = (known after apply)
      	+ description            = "Managed by Terraform"
      	+ egress                 = (known after apply)
      	+ id                     = (known after apply)
      	+ ingress                = [
          + {
              + cidr_blocks      = [
                  + "100.24.0.0/13",
                  + "107.20.0.0/14",
                  + "110.238.2.0/23",
                  + "13.128.0.0/16",
	...
		

APPLY
-----
Apply the planned resources
	terminal --> terraform apply
Check on AWS/EC2 if the instance is created and AWS/EC2/Security group if the security group is created.
In the security group details we can see the avalable IPs for this instance.
	- on the tags page we can find the craetion date and SyncToken

DESTROY
-------
Destroy terraform resources
	terminal --> terrafomr destroy
	terminal --> yes			# confirm destruction of the resources




30. Output Attribute in TF
==========================

DEPLOYMENT AUTOMATION
---------------------

➢ Terraform Keeps Output of all resources and it’s attribute.

➢ Output in terraform can be queried and retain.
	- retain the public/private IPs of the instaces in case of Ansible playbooks

➢ Output values are like the return values of a Terraform module, and have several uses:
	➢ A child module can use outputs to expose a subset of its resource attributes to a parent module
		- data from submodule can be accessed by the paret module
	➢ A root module can use outputs to print certain values in the CLI output after running terraform apply.
		- print out info for reporting purposes on aplly command
	➢ When using remote state, root module outputs can be accessed by other configurations via a terraform_remote_state data source.



➢ Each output value exported by a module must be declared using an output block:
------------------------------------------------------
output "instance_ip_addr" {				# define output block
  value = aws_instance.server.private_ip		# define instance parameter we want to get
}
------------------------------------------------------

➢ The value argument takes an expression whose result is to be returned to the user.

➢ Outputs are only rendered when Terraform applies your plan. Running terraform plan will not render outputs.
	- IMPORTANT - ONLY ON APPLY COMMAND, (NOT ON PLAN)



➢ Outputs can also be used in Scripts.

------------------------------------------------------
resource "aws_instance" "MyFirstInstnace" {			# instance
  ami = data.aws_ami.latest-ubuntu.id
  instance_type = "t2.micro"
  availability_zone = data.aws_availability_zones.avilable.names[1]

  tags = {
    Name = "custom_instance"
  }

  provisionor "local-exec" {								# local-exec provisioner
    command = "echo aws_instance.MyFirstInstnace.private_ip >> privateips.txt"		# save instance private IP in file
  }
}
------------------------------------------------------






31. Lab : Output Attribute in TF
================================

createInstance.tf
------------------------------------------------------

data "aws_availability_zones" "avilable" {}

data "aws_ami" "latest-ubuntu" {
  most_recent = true
  owners = ["099720109477"]

  filter {
    name = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }
}


resource "aws_instance" "MyFirstInstnace" {
  ami           = data.aws_ami.latest-ubuntu.id
  instance_type = "t2.micro"
  availability_zone = data.aws_availability_zones.avilable.names[1]

  provisioner "local-exec" {
    command = "echo ${aws_instance.MyFirstInstnace.private_ip} >> my_private_ips.txt"
  }

  tags = {
    Name = "custom_instance"
  }
}

output "public_ip" {
  value = aws_instance.MyFirstInstnace.public_ip 
}
------------------------------------------------------






32. Remote State in Terraform
=============================



33. Lab : Remote State in Terraform
===================================



