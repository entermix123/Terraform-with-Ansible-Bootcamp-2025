Content
=======

Section 8: Terraform for AWS Cloud Part II
47. AWS RDS Basics
48. Lab : Create RDS
49. AWS Access and Identity Management
50. Lab : IAM Users and Groups
51. Lab : AWS IAM Roles
52. EC2 Instance Autoscaling
53. Lab : EC2 Instance Autoscaling
54. Your Reviews are Important!
55. Load Balancing in AWS
56. Lab : AWS Load Balancing



47. AWS RDS Basics
==================


RDS - Amazon Relational Database Service
----------------------------------------

➢ It’s Amazon managed DB Solution.
	- Amazon will maintain the complete DB service from backup to upgrade

➢ RDS Manages BackUp, Software Patching, Auto Failure Detection and recovery
	- RD service created on HA mode - high availability mode (services created on 2-3 availability zones, two of them are synced - redundant)
	- we can provide backup plan - when to perform backups and for how many days we want to keep our backup
	- all updates, upgrades and paches are executed by amazon with no service desruption

➢ User have Automatic Backup and manual Backup Options.



RDS Supports below RDBMS
------------------------
	➢ MySQL
	➢ MariaDB
	➢ Postgre SQL
	➢ Oracle
	➢ MS SQL Server

➢ RDS have HA functionality with auto replication.
	- set redundant service on close availability zone, so when the primary service is not working, the redundant service assure the sevice availability - takes the traffic


RDS Auto Scaling
----------------
➢ RDS auto scale storage capacity in response to growing db workload with Zero Down Time.


Steps to create RDS Instances:
------------------------------

➢ Create a Subnet Group - Allow in which Subnets the database will be in.
	- if RDS in HA mode we have to define more than one Subnet, so both of the instance are created in different subnet
	- we need subnet group form more thatn one subnet - private subnet

➢ Create Parameter Group - Allow to change setting in DB using parameters.
	- DB settings are managed with Parameter Group, RDS do NOT allow ssh connection
	- we can manage RDS only from parameters

➢ Create Security group - Allow incoming traffic to RDS instance.
	- we need to grand connection ONLY to the instances that will perform actions on RDS 

➢ Create RDS Instance Itself.
	- when all requirements above are covered, we can create RDS instance


RDS AWS Components:
-------------------
	➢ DB Instances
	➢ Regions and Availability Zones
	➢ Security Groups
	➢ DB Parameter Groups
	➢ DB Option Groups




48. Lab : Create RDS
====================

We will
	1. Create RDS
	2. Login to the RDS instance

We have 6 files
---------------
➢ createInstance.tf
➢ provider.tf
➢ variables.tf
➢ vpc.tf
➢ security_group.tf
➢ rds.tf



createInstance.tf
--------------------------------------------------
resource "aws_key_pair" "levelup_key" {			# KeyPair for terraform AWS login
    key_name = "levelup_key"				# key name
    public_key = file(var.PATH_TO_PUBLIC_KEY)		# public key path to location
}

#Create AWS Instance
resource "aws_instance" "MyFirstInstnace" {
  ami           = lookup(var.AMIS, var.AWS_REGION)	# amazone machine image AMI - image and region
  instance_type = "t2.micro"				# type hardware - t2.micro - free tier
  availability_zone = "us-east-2a"			# zone - a, b, c or d
  key_name      = aws_key_pair.levelup_key.key_name			# path of the access key
  vpc_security_group_ids = [aws_security_group.allow-levelup-ssh.id]	# VPC security group ID
  subnet_id = aws_subnet.levelupvpc-public-1.id				# our first public subnet ID

  tags = {								# tag
    Name = "custom_instance"
  }
}

output "public_ip" {							# print instance public ip on launch
  value = aws_instance.MyFirstInstnace.public_ip 
}
--------------------------------------------------



AWS VPC
-------
➢ search 'aws vpc' in the search bar on left and choose 'aws_vpc'
   ➢ Example usage and syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc#example-usage
   ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc#argument-reference

AWS SUBNET
----------
➢ search 'aws subnet'
   ➢ Example usage and syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet#example-usage
   ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet#argument-reference

AWS INTERNET GATEWAY
--------------------
➢ search 'aws internet gateway'
  ➢ Example syntax - ttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway#argument-reference

AWS ROUTE TABLE
---------------
➢ search 'aws route table'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table#argument-reference

AWS ROUTE TABLE ASSOCIATION
---------------------------
➢ search 'aws route table assocation'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association#argument-reference


vpc.tf
--------------------------------------------------
#Create AWS VPC
resource "aws_vpc" "levelupvpc" {
  cidr_block       = "10.0.0.0/16"	# Classless Inter-Domain Routing (CIDR) block.
  instance_tenancy = "default"		# more than one instance can run on the same hardware - preffered - minimized consts
  enable_dns_support   = "true"
  enable_dns_hostnames = "true"	  # create hostname and dns of our instance name, the name of our aws instance will work as dns


  tags = {
    Name = "levelupvpc"
  }
}

# Public Subnets in Custom VPC
resource "aws_subnet" "levelupvpc-public-1" {		# public subnet
  vpc_id                  = aws_vpc.levelupvpc.id	# ID of our VPC
  cidr_block              = "10.0.1.0/24"		# IP range - we can't overlap with other subnets IP ranges
  map_public_ip_on_launch = "true"		# on launch the public IP will be asociated with this instance - public subnet
  availability_zone       = "us-east-2a"	# first availability zone for public subnet

  tags = {					# tag of the subnet
    Name = "levelupvpc-public-1"
  }
}

resource "aws_subnet" "levelupvpc-public-2" {		# second public subnet
  vpc_id                  = aws_vpc.levelupvpc.id	# ID of our VPC
  cidr_block              = "10.0.2.0/24"		# IP range - we can't overlap with other subnets IP ranges
  map_public_ip_on_launch = "true"			# map the public IP to this ubnet - public subnet
  availability_zone       = "us-east-2b"		# second availability zone for public subnet
		
  tags = {						# tag the subnet
    Name = "levelupvpc-public-2"
  }
}

resource "aws_subnet" "levelupvpc-public-3" {		# third public subnet
  vpc_id                  = aws_vpc.levelupvpc.id	# ID of our VPC
  cidr_block              = "10.0.3.0/24"		# IP range - we can't overlap with other subnets IP ranges
  map_public_ip_on_launch = "true"			# map the public IP to this ubnet - public subnet
  availability_zone       = "us-east-2c"		# third availability zone for public subnet

  tags = {						# tag
    Name = "levelupvpc-public-3"
  }
}

# Private Subnets in Custom VPC
resource "aws_subnet" "levelupvpc-private-1" {		# first private subnet
  vpc_id                  = aws_vpc.levelupvpc.id	# ID of our VPC
  cidr_block              = "10.0.4.0/24"		# IP range - we can't overlap with other subnets IP ranges
  map_public_ip_on_launch = "false"			# not mapping the public IP - private subnet
  availability_zone       = "us-east-2a"		# first availability zone for private subnet

  tags = {						# tag
    Name = "levelupvpc-private-1"
  }
}

resource "aws_subnet" "levelupvpc-private-2" {		# second private subnet
  vpc_id                  = aws_vpc.levelupvpc.id	# ID of our VPC
  cidr_block              = "10.0.5.0/24"		# IP range - we can't overlap with other subnets IP ranges
  map_public_ip_on_launch = "false"			# not mapping the public IP - private subnet
  availability_zone       = "us-east-2b"		# second availability zone for private subnet

  tags = {						# tag
    Name = "levelupvpc-private-2"
  }
}

resource "aws_subnet" "levelupvpc-private-3" {		# third private subnet
  vpc_id                  = aws_vpc.levelupvpc.id	# ID of our VPC
  cidr_block              = "10.0.6.0/24"		# IP range - we can't overlap with other subnets IP ranges
  map_public_ip_on_launch = "false"			# not mapping the public IP - private subnet
  availability_zone       = "us-east-2c"		# third availability zone for private subnet

  tags = {						# tag
    Name = "levelupvpc-private-3"
  }
}

# Custom internet Gateway
resource "aws_internet_gateway" "levelup-gw" {		# internet Gateway resource and name
  vpc_id = aws_vpc.levelupvpc.id			# ID of our VPC

  tags = {						# tag internet gateway
    Name = "levelup-gw"
  }
}

#Routing Table for the Custom VPC			
resource "aws_route_table" "levelup-public" {		# routing table resource and name
  vpc_id = aws_vpc.levelupvpc.id			# ID of our VPC
  route {
    cidr_block = "0.0.0.0/0"				# all IPs
    gateway_id = aws_internet_gateway.levelup-gw.id	# our internet gateway ID
  }

  tags = {						# tag routing table
    Name = "levelup-public-1"
  }
}

resource "aws_route_table_association" "levelup-public-1-a" {		# associate with our first public subnet
  subnet_id      = aws_subnet.levelupvpc-public-1.id			# our first public subnet id
  route_table_id = aws_route_table.levelup-public.id			# our route table id
}

resource "aws_route_table_association" "levelup-public-2-a" {		# associate with our second public subnet
  subnet_id      = aws_subnet.levelupvpc-public-2.id			# our second public subnet id
  route_table_id = aws_route_table.levelup-public.id			# our route table id
}

resource "aws_route_table_association" "levelup-public-3-a" {		# associate with our third public subnet
  subnet_id      = aws_subnet.levelupvpc-public-3.id			# our third public subnet id
  route_table_id = aws_route_table.levelup-public.id			# our route table id
}
--------------------------------------------------



security_group.tf
--------------------------------------------------
#Security Group for levelupvpc
resource "aws_security_group" "allow-levelup-ssh" {		# security group resource
  vpc_id      = aws_vpc.levelupvpc.id				# our VPC id
  name        = "allow-levelup-ssh"				# SG name
  description = "security group that allows ssh connection"	# short description

  egress {					# egress rule - outbond traffic
    from_port   = 0				# from port traffic accepted - all ports
    to_port     = 0				# to port traffic accepted - all ports
    protocol    = "-1"				# "-1" - all protocols, we can use also list []
    cidr_blocks = ["0.0.0.0/0"]			# all IPs for outgoing traffic - best practice
  }  

  ingress {					# ingress rule - inbound traffic
    from_port   = 22				# from port 22 only incoming traffic
    to_port     = 22				# to port 22 only incoming traffic
    protocol    = "tcp"				# tcp protocol only
    cidr_blocks = ["0.0.0.0/0"]			# all IPs - not recommended
  }	# Best prectice - We should specify only the IP of our local PC/box that will execute terraform commands
  
  tags = {					# tag
    Name = "allow-levelup-ssh"
  }
}

#Security Group for MariaDB				
resource "aws_security_group" "allow-mariadb" {		# mariadb security group 
  vpc_id      = aws_vpc.levelupvpc.id			# our VPC id 
  name        = "allow-mariadb"				# SG name
  description = "security group for Maria DB"		# short description

  egress {					# ingress rule - inbound traffic
    from_port   = 0				# from port traffic accepted - all ports
    to_port     = 0				# to port traffic accepted - all ports
    protocol    = "-1"				# "-1" - all protocols, we can use also list []
    cidr_blocks = ["0.0.0.0/0"]			# all IPs for outgoing traffic - best practice
  }

  ingress {					# ingress rule - inbound traffic
    from_port   = 3306				# from port 3306 only incoming traffic
    to_port     = 3306				# to port 3306 only incoming traffic
    protocol    = "tcp"				# tcp protocol only
    security_groups = [aws_security_group.allow-levelup-ssh.id]	   # SG of the aws instance that will access the MariaDB
  }
  
  tags = {					# tag
    Name = "allow-mariadb"
  }
}
--------------------------------------------------



We can see all parameters and syntax for the VPC - https://registry.terraform.io/providers/hashicorp/aws/latest/docs

AWS DB SUBNET
-------------
➢ search 'aws db subnet group' (under RDS Relational Database)
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_subnet_group#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_subnet_group#argument-reference


AWS DB PARAMETER GROUP
----------------------
➢ search 'aws db parameter group' (under RDS Relational Database) - choose the specific DB, for this example MariaDB
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_parameter_group#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_parameter_group#argument-reference


AWS DB INSTANCE
---------------
➢ search 'aws db instance' (under RDS Relational Database) - for this example MariaDB
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/db_instance#argument-reference
  ➢ MariaDB Latest Version - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.MariaDB.Parameters.html
  ➢ MariaDB latest engine version - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MariaDB.Concepts.VersionMgmt.html


rds.tf
--------------------------------------------------
#RDS Resources
resource "aws_db_subnet_group" "mariadb-subnets" {		# db subnet group
  name        = "mariadb-subnets"				# db subnet name
  description = "Amazon RDS subnet group"			# short description
  subnet_ids  = [aws_subnet.levelupvpc-private-1.id, aws_subnet.levelupvpc-private-2.id]  
}	# set 2 id of our private subnet groups - HA high availability

#RDS Parameters
resource "aws_db_parameter_group" "levelup-mariadb-parameters" {	# db parameter group
  name        = "levelup-mariadb-parameters"				# db parameter group name
  family      = "mariadb10.4"						# db version - latest is prefered
  description = "MariaDB parameter group"				# short description

  parameter {
    name  = "max_allowed_packet"
    value = "16777216"			# random number
  }
}

#RDS Instance properties
resource "aws_db_instance" "levelup-mariadb" {
  allocated_storage       = 20             # 20 GB of storage
  engine                  = "mariadb"
  engine_version          = "10.4.8"
  instance_class          = "db.t2.micro"  # use micro if you want to use the free tier
  identifier              = "mariadb"
  username                = "root"           # username
  password                = "mariadb141"     # password
  db_subnet_group_name    = aws_db_subnet_group.mariadb-subnets.name			# link hte db subnet
  parameter_group_name    = aws_db_parameter_group.levelup-mariadb-parameters.name	# link the db parameter group
  multi_az                = "false"            # set to true to have high availability: 2 instances synchronized with each other
  vpc_security_group_ids  = [aws_security_group.allow-mariadb.id]  	# db security group id
  storage_type            = "gp2"					# type disk
  backup_retention_period = 30                                          # how long you’re going to keep your backups
  availability_zone       = aws_subnet.levelupvpc-private-1.availability_zone # prefered AZ - same as the first private subnet 
  skip_final_snapshot     = true                                        # skip final snapshot when doing terraform destroy
  
  tags = {								# tag
    Name = "levelup-mariadb"
  }
}

output "rds" {								# print the endpoint for mariadb RDS on launch
  value = aws_db_instance.levelup-mariadb.endpoint
}
--------------------------------------------------


provider.tf
--------------------------------------------------
provider "aws" {
  access_key = var.AWS_ACCESS_KEY
  secret_key = var.AWS_SECRET_KEY
  region     = var.AWS_REGION
}
--------------------------------------------------


variables.tf
--------------------------------------------------
variable "AWS_ACCESS_KEY" {
    type = string
    default = "AKIAY65Y5OPLU3XH5T6O"
}

variable "AWS_SECRET_KEY" {}

variable "AWS_REGION" {
default = "us-east-2"
}

variable "AMIS" {
    type = map
    default = {
        us-east-1 = "ami-0f40c8f97004632f9"
        us-east-2 = "ami-05692172625678b4e"
        us-west-2 = "ami-0352d5a37fb4f603f"
        us-west-1 = "ami-0f40c8f97004632f9"
    }
}

variable "PATH_TO_PRIVATE_KEY" {
  default = "levelup_key"
}

variable "PATH_TO_PUBLIC_KEY" {
  default = "levelup_key.pub"
}

variable "INSTANCE_USERNAME" {
  default = "ubuntu"
}
--------------------------------------------------



Login to the igitalOcean ubuntu and pull the files from github.
	terminal --> ssh root@IP
	terminal --> password

Update the linux package manager
	terminal --> sudo apt-get update

Pull the repo
	terminal --> git clone repo_url
	or
	terminal --> git pull

We need to install AWS CLI on the machine
	terminal --> sudo apt-get install awscli
	terminal --> y					# confirm


INIT
----
Initialize terrafomr
	terminal --> terraform init

Generate private and public key
	terminal --> ssh-keygen -f levelup_key
	terminal --> enter
	terminal --> enter

Verify key creation
	terminal --> ls
	# we should have 2 new files - levelup-key and levelup-key.pub

PLAN
----
Plan terraform resources
	terminal --> terraform plan
	terminal --> AWS Secret access key

	# the plan should be successful and we can review the logs
	# result: 	
		Plan: 19 to add, 0 to change, 0 to destroy.

		Changes to Outputs:
  		  + public_ip = (known after apply)
  		  + rds       = (known after apply)	

APPLY
-----
Apply the plan made on the DigitalOcean Ubuntu machine
	terminal --> terraform apply
	terminal --> xxxxxxxxxxxxxxxxxxxxxx		# provide the seucrity key
	terminal --> yes				# confirm

It may take from 5 to 15 minutes for resource creation.
On the console we can see instance public ip and mariadb endpoint.

Check resources creation on AWS/EC2:

We can connect the AWS instance from local PC/box.
Copy the public IP from the console
	terminal --> ssh instance_public_ip -l ubuntu -i levelup_key

	# ssh instance_public_ip		- connect to the instance
	# -l ubuntu				- login as ubuntu user
	# -i levelup_key			- use terraform public key

Now we are logged into the instance.

Update the instance package manager
	instance terminal --> sudo apt-get update

Install mysql-client
	instance terminal --> sudo apt-get install mysql-client
	instance terminal --> yes			# confirm

Connect to MariaDB with te mysql-client
	instance terminal --> mysql -u root -h mariadb.cyfn1frcqyc9.us-east-2.rds.amazonaws.com -p'maria141'

	# mysql				- use mysql
	# -u root			- set user - user is set in the rds.tf/"aws_db_instance" section
	# -h mariadb.cyfn1frcqyc9.us-east-2.rds.amazonaws.com - the endpoint of the db - we can copy from the console after apply
	# -p'mariadb141'		- password - password is set in the rds.tf/"aws_db_instance" section, no space "-p'pass'"

Now we are logged in on the MariaDB instance
We can list the databases
	mariadb terminal --> show databases;

	# result: default databases in table fomrat - 6 dbs

Exit MariaDB instance
	mariadb terminal --> exit

Exit the AWS instance
	instance terminal --> exit

We can check MariaDB on AWS/RDS/DB Instances


DESTROY
-------
We can now destroy the created resources on AWS
	terminal --> terraform destroy
	terminal --> xxxxxxxxxxxxxxxxxxxxxx	# provide the seucrity key
	terminal --> yes			# confirm destruction



SUMMARY

Steps to create RDS Instances:
------------------------------

➢ Create a Subnet Group - Allow in which Subnets the database will be in. 
	- vpc.tf (internet gateway and subnets), security_group.tf

➢ Create Parameter Group - Allow to change setting in DB using parameters. 
	- rds.tf

➢ Create Security group - Allow incoming traffic to RDS instance. 
	- security_group.tf

➢ Create RDS Instance Itself. 
	- rds.tf







49. AWS Access and Identity Management
======================================

Managing the security access with AIM (principal) User

➢ IAM - Access and Identity Management.

➢ IAM enables you to manage access to AWS services and resources in a very secure manner.

➢ AWS Identity and Access Management (IAM) is a web service for securely controlling access to AWS resources.



How Does IAM Work?
------------------

➢ Principal is an entity that can perform actions on an AWS resource. A user, a role or an application can be a principal.
	- IAM principal can be a user, role or application

➢ Authentication is the process of confirming the identity of the principal trying to access an AWS product. The principal must provide its credentials or required keys for authentication.

➢ Request: A principal sends a request to AWS specifying the action and which resource should perform it.
	- principal will specify creadentials, resource and type action

➢ Authorization: By default, all resources are denied. IAM authorizes a request only if all parts of the request are allowed by a matching policy. After authenticating and authorizing the request, AWS approves the action.

➢ Actions are used to view, create, edit or delete a resource.

➢ Resources: A set of actions can be performed on a resource related to your AWS account.



Components of IAM
-----------------

➢ Users : IAM user is an identity with an associated credential and permissions attached to it.
	- we need to assign creadentials and permissions to the user

➢ This could be an actual person who is a user, or it could be an application that is a user.

➢ Each IAM user is associated with only one AWS account.



Components of IAM
-----------------

➢ Groups : A collection of IAM users is an IAM group.

➢ IAM groups used to specify permissions for multiple users so that any permissions applied to the group are applied to the individual users in that group.
	- Developer group - Role Base Access Control - RBAC

➢ New member of the Group inherit the policies and permissions of the Group automatically.


Components of IAM
-----------------

➢ Policies : IAM policy sets permission and controls access to AWS resources.

➢ Policy is a JSON data document.

➢ Permissions specify who has access to the resources and what actions they can perform. Policy would contain the following
information:
	➢ Who can access it
	➢ What actions that user can take
	➢ Which AWS resources that user can access
	➢ When they can be accessed (timeframe)


Components of IAM
-----------------

➢ Roles : IAM role is a set of permissions that define what actions are allowed and denied by an entity in the AWS console.

➢ Role permissions are temporary credentials.
	- we set permision to backend to modify the DB and not frontend service.





50. Lab : IAM Users and Groups
==============================

We have 3 files
---------------
➢ iamuser.tf
➢ providers.tf
➢ variables.tf

We will craete IAM user and will NOT destroy it with terraform. Thi IAM user will be used in the next lectures and Labs.
	- NO terraform destroy


AWS IAM USER
------------
➢ search 'aws iam user'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user#argument-reference
  ➢ Attribute Reference - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user#attribute-reference


AWS IAM GROUP MEMBERSHIP
------------------------
➢ search 'aws iam group membership'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_group_membership#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_group_membership#argument-reference
  ➢ Attribute Reference - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_group_membership#attribute-reference


AWS IAM POLICY ATTACHMENT
-------------------------
➢ search 'aws iam policy attachment'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy_attachment#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy_attachment#argument-reference
  ➢ Attribute Reference - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy_attachment#attribute-reference



iamuser.tf
--------------------------------------------------
#TF File for IAM Users and Groups

resource "aws_iam_user" "adminuser1" {			# admin user 1
  name = "adminuser1"					# name for user 1
}

resource "aws_iam_user" "adminuser2" {			# admin user 2
  name = "adminuser2"					# name for admin user 2 
}

# Group TF Definition
resource "aws_iam_group" "admingroup" {			# admin group
  name = "admingroup"					# name of the group
}

#Assign User to AWS Group
resource "aws_iam_group_membership" "admin-users" {	# group membership 
  name = "admin-users"					# name of the membership
  users = [						# list of the users
    aws_iam_user.adminuser1.name,
    aws_iam_user.adminuser2.name,
  ]
  group = aws_iam_group.admingroup.name			# group of the users
}

#Policy for AWS Group
resource "aws_iam_policy_attachment" "admin-users-attach" {	# policy resource
  name       = "admin-users-attach"				# policyresource  name
  groups     = [aws_iam_group.admingroup.name]			# associate groups
  policy_arn = "arn:aws:iam::aws:policy/AdministratorAccess"	# set policy rights - administrative access
}
--------------------------------------------------



providers.tf
--------------------------------------------------
provider "aws" {
  access_key = var.AWS_ACCESS_KEY
  secret_key = var.AWS_SECRET_KEY
  region     = var.AWS_REGION
}
--------------------------------------------------


variables.tf
--------------------------------------------------
variable "AWS_ACCESS_KEY" {
    type = string
    default = "AKIAY65Y5OPLU3XH5T6O"
}

variable "AWS_SECRET_KEY" {}

variable "AWS_REGION" {
default = "us-east-2"
}

variable "AMIS" {
    type = map
    default = {
        us-east-1 = "ami-0f40c8f97004632f9"
        us-east-2 = "ami-05692172625678b4e"
        us-west-2 = "ami-0352d5a37fb4f603f"
        us-west-1 = "ami-0f40c8f97004632f9"
    }
}

variable "PATH_TO_PRIVATE_KEY" {
  default = "levelup_key"
}

variable "PATH_TO_PUBLIC_KEY" {
  default = "levelup_key.pub"
}

variable "INSTANCE_USERNAME" {
  default = "ubuntu"
}
--------------------------------------------------



Login to the igitalOcean ubuntu and pull the files from github.
	terminal --> ssh root@IP
	terminal --> password

Update the linux package manager
	terminal --> sudo apt-get update

Pull the repo
	terminal --> git clone repo_url
	or
	terminal --> git pull

We need to install AWS CLI on the machine
	terminal --> sudo apt-get install awscli
	terminal --> y					# confirm


INIT
----
Initialize terrafomr
	terminal --> terraform init

Generate private and public key
	terminal --> ssh-keygen -f levelup_key
	terminal --> enter
	terminal --> enter

Verify key creation
	terminal --> ls
	# we should have 2 new files - levelup-key and levelup-key.pub

PLAN
----
Plan terraform resources
	terminal --> terraform plan
	terminal --> AWS Secret access key

	# the plan should be successful and we can review the logs
	# result: 	
		Plan: 5 to add, 0 to change, 0 to destroy.


APPLY
-----
Apply the plan made on the DigitalOcean Ubuntu machine
	terminal --> terraform apply
	terminal --> xxxxxxxxxxxxxxxxxxxxxx		# provide the seucrity key
	terminal --> yes				# confirm

# result:
aws_iam_user.adminuser1: Creating...
aws_iam_user.adminuser2: Creating...
aws_iam_group.admingroup: Creating...
aws_iam_user.adminuser2: Creation complete after 1s [id=adminuser2]
aws_iam_user.adminuser1: Creation complete after 1s [id=adminuser1]
aws_iam_group.admingroup: Creation complete after 1s [id=admingroup]
aws_iam_group_membership.admin-users: Creating...
aws_iam_policy_attachment.admin-users-attach: Creating...
aws_iam_policy_attachment.admin-users-attach: Creation complete after 0s [id=admin-users-attach]
aws_iam_group_membership.admin-users: Creation complete after 0s [id=admin-users]


Check resources creation on 
Users - AWS/IAM/Users
User Groups - AWS/IAM/Users groups - admingroup is new, inside we have the two users: adminuser1 and adminuser2
	- inside User details we can see AdministratorAccess permissions


NO DESTROY
----------





51. Lab : AWS IAM Roles
=======================

We have 5 files
---------------
➢ createInstance.tf
➢ iamroles.tf
➢ s3bucket.tf
➢ provider.tf
➢ variables.tf



createInstance.tf
--------------------------------------------------
resource "aws_key_pair" "levelup_key" {			# KeyPair resource
    key_name = "levelup_key"				# access key name
    public_key = file(var.PATH_TO_PUBLIC_KEY)		# path to location of the key
}

#Create AWS Instance
resource "aws_instance" "MyFirstInstnace" {		# aws instance resource
  ami           = lookup(var.AMIS, var.AWS_REGION)	# Amazon Machine Image and Region
  instance_type = "t2.micro"				# hardware type - t2.micro free tier
  availability_zone = "us-east-2a"			# availability zone a, b, c or/and d
  key_name      = aws_key_pair.levelup_key.key_name	# used access key name
  
  iam_instance_profile = aws_iam_instance_profile.s3-levelupbucket-role-instanceprofile.name	# set instance profile

  tags = {						# tag
    Name = "custom_instance"
  }
}

output "public_ip" {					# print instance public ip on the console on launch
  value = aws_instance.MyFirstInstnace.public_ip 
}
--------------------------------------------------




AWS IAM ROLE
------------
➢ search 'aws iam role'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role#argument-reference


AWS IAM ROLE POLICY
-------------------
➢ search 'aws iam role'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy#argument-reference


AWS IAM INSTANCE PROFILE
------------------------
➢ search 'aws iam role'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_instance_profile#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_instance_profile#argument-reference



iamroles.tf
--------------------------------------------------
#Roles to access the AWS S3 Bucket
resource "aws_iam_role" "s3-levelupbucket-role" {	# iam role resource
  name               = "s3-levelupbucket-role"		# iam role name
  assume_role_policy = <<EOF				# attach a policy
{							# inside EOF block we can define policy in JSON format
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ec2.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF

}

#Policy to attach the S3 Bucket Role
resource "aws_iam_role_policy" "s3-levelupmybucket-role-policy" {	# policy resource
  name = "s3-levelupmybucket-role-policy"				# policy name
  role = aws_iam_role.s3-levelupbucket-role.id				# our iam role id
  policy = <<EOF							# in EOF block we define policy in JSON format
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
              "s3:*"						# allow action on s3 resource
            ],
            "Resource": [
              "arn:aws:s3:::levelup-bucket-141421",		# bucket name
              "arn:aws:s3:::levelup-bucket-141421/*"		# all in the bucket
            ]
        }
    ]
}
EOF

}

#Instance identifier
resource "aws_iam_instance_profile" "s3-levelupbucket-role-instanceprofile" {	# instance identifier - instance profile
  name = "s3-levelupbucket-role"						# instance profile name
  role = aws_iam_role.s3-levelupbucket-role.name				# attached our role
}
--------------------------------------------------




AWS S3 BUCKET
-------------
➢ search 'aws s3 bucket'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#argument-reference


s3bucket.tf
--------------------------------------------------
#Create AWS S3 Bucket

resource "aws_s3_bucket" "levelup-s3bucket" {		# aws s3 bucket resource
  bucket = "levelup-bucket-141421"			# bucket name - must be globally unique

  tags = {						# tag
    Name = "levelup-bucket-141421"
  }
}
--------------------------------------------------



provider.tf
--------------------------------------------------
provider "aws" {
  access_key = var.AWS_ACCESS_KEY
  secret_key = var.AWS_SECRET_KEY
  region     = var.AWS_REGION
}
--------------------------------------------------


variables.tf
--------------------------------------------------
variable "AWS_ACCESS_KEY" {
    type = string
    default = "AKIAY65Y5OPLU3XH5T6O"
}

variable "AWS_SECRET_KEY" {}

variable "AWS_REGION" {
default = "us-east-2"
}

variable "AMIS" {
    type = map
    default = {
        us-east-1 = "ami-0f40c8f97004632f9"
        us-east-2 = "ami-05692172625678b4e"
        us-west-2 = "ami-0352d5a37fb4f603f"
        us-west-1 = "ami-0f40c8f97004632f9"
    }
}

variable "PATH_TO_PRIVATE_KEY" {
  default = "levelup_key"
}

variable "PATH_TO_PUBLIC_KEY" {
  default = "levelup_key.pub"
}

variable "INSTANCE_USERNAME" {
  default = "ubuntu"
}
--------------------------------------------------


Login to the igitalOcean ubuntu and pull the files from github.
	terminal --> ssh root@IP
	terminal --> password

Update the linux package manager
	terminal --> sudo apt-get update

Pull the repo
	terminal --> git clone repo_url
	or
	terminal --> git pull

We need to install AWS CLI on the machine
	terminal --> sudo apt-get install awscli
	terminal --> y					# confirm


INIT
----
Initialize terrafomr
	terminal --> terraform init

Generate private and public key
	terminal --> ssh-keygen -f levelup_key
	terminal --> enter
	terminal --> enter

Verify key creation
	terminal --> ls
	# we should have 2 new files - levelup-key and levelup-key.pub

PLAN
----
Plan terraform resources
	terminal --> terraform plan
	terminal --> AWS Secret access key

	# the plan should be successful and we can review the logs
	# result: 	
		Plan: 6 to add, 0 to change, 0 to destroy.

		Changes to Outputs:
  		  + public_ip = (known after apply)	

APPLY
-----
Apply the plan made on the DigitalOcean Ubuntu machine
	terminal --> terraform apply
	terminal --> xxxxxxxxxxxxxxxxxxxxxx		# provide the seucrity key
	terminal --> yes				# confirm

On the console we can see instance public ip 

Check resources creation on AWS/EC2 and AWS/S3

We can connect the AWS instance from local PC/box.
Copy the public IP from the console
	terminal --> ssh instance_public_ip -l ubuntu -i levelup_key

	# ssh instance_public_ip		- connect to the instance
	# -l ubuntu				- login as ubuntu user
	# -i levelup_key			- use terraform public key

Now we are logged into the instance.

Switch to root user
	instance terminal --> sudo -s

Update the instance package manager
	instance terminal --> apt-get update

We will create content to S3 bucket. For this purpose we need to install aws cli and use the instance profile.

Install python (required for aws cli)
	instance terminal --> apt-get install python-pip python-dev
	instance terminal --> yes					# confirm

Install aws cli with pip
	instance terminal --> pip install awscli

Create simple file with message
	instance terminal --> echo "Hi, this is my TF Class for AWS IAM" > myfile.txt

Confirm file creation and print the content
	instance terminal --> ls
	instance terminal --> cat myfile.txt

Upload thi sfile in AWS S3 bucket
	instance terminal --> aws s3 cp myfile.txt s3://levelup-bucket-141421

	# aws 					- common aws cli command
	# s3 					- target resource 
	# cp myfile.txt				- copy command and the target file
	# s3://levelup-bucket-141421		- name of the s3 resource

	# result: upload: ./myfile.txt to s3://levelup-bucket-141421

We can see that our instance have complete access to our S3 bucket and we can perform actions over it.
	- the instance use the instance profiler that use s3 bucket role, so the instance can perform any action on the S3 bucket
		- upload, craete, delete, modify etc.

We can check on AWS/S3 for our myfile.txt file.
We can see the access role on AWS/EC2/Details.
	
Exit the AWS instance
	instance terminal --> exit


DESTROY
-------
We can now destroy the created resources on AWS
	terminal --> terraform destroy
	terminal --> xxxxxxxxxxxxxxxxxxxxxx	# provide the seucrity key
	terminal --> yes			# confirm destruction







52. EC2 Instance Autoscaling
============================

Autoscaling is available on multiple resources on AWS - load balancer, EC2, IAM etc. We will look over autoscaling on EC2.

➢ Auto Scaling ensures that Amazon EC2 instances are sufficient to run your application.
	- increatese number of servers when we have more online users
	- decrease number of servers when we have lower online users
	- const friendly

➢ When the number of requests increases the load on the servers also increases, AWS will identify and autoscale the resource as per the defined configuration.
	- autoscaling is not configured by default on AWS. We need to configure it if we want to use it for EC2 instances.

➢ Autoscaling group is mandatory to Auto Scale the EC2 Instances.



AutoScaling Components
----------------------

➢ Groups : Logical groups which contain the collection of EC2 instances with similar characteristics for scaling and management purpose.

➢ Auto-scaling group also maintains a fixed number of instances even if an instance becomes unhealthy.
	- if 3 instances are configured, munimum 3 will be up at any time no matter of the traffic

➢ Autoscaling group keep checking the EC2 Instances using the HealthCheck.
	- if instance is unhelthy, AWS will terminate it and start new one

➢ If any instance becomes unhealthy, the auto-scaling group terminates the unhealthy instance and launches another instance to replace it.

➢ Auto scaling groups can increase or decrease the number of EC2 Instances.
	- we need to create policies for decreacing number of instances when traffic is declining.


AutoScaling Components
----------------------

➢ Launch Configurations : Launch configuration is a template used by auto scaling group to launch EC2 instances.

➢ User specify the Amazon Machine Image (AMI), instances type, key pair, and security groups etc.. while creating the launch configuration.

➢ User can also edit the launch configuration.



AutoScaling Components
----------------------

➢ Scaling Plan : Scaling plans tells Auto Scaling when and how to scale.

➢ Maintaining Current instance level at all time - User can configure and maintain a specified number of running instances at all the time in the auto scaling group.
	- inluded also scripts that will be executed after the boot

➢ If any unhealthy instance occurs, auto-scaling terminates that instance and launches new instances to replace it

➢ Manual Scaling - In Manual scaling, you specify only the changes in maximum, minimum, or desired capacity of your auto scaling
groups. Auto-scaling maintains the instances with updated capacity.



AutoScaling Components
----------------------

➢ Schedule Base Scaling : User can create a scheduled action which tells Amazon EC2 auto-scaling to perform the scaling action based on the specific time.

➢ Scale based on demand : This is the most advanced scaling model, resources scales by using a scaling policy.
	- most advanced and complex scaling model
	- we need to define increasing and decreasing scaling policies
	- the autoscaling depend on the load and the traffic of our application
	- const beneficial




53. Lab : EC2 Instance Autoscaling
==================================

We have 3 files
---------------
➢ autoscaling.tf
➢ provider.tf
➢ variables.tf



AWS LAUNCH CONFIGURATION
------------------------
➢ search 'aws launch configuration'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/launch_configuration#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/launch_configuration#argument-reference


AWS AUTOSCALING GROUP
---------------------
➢ search 'aws autoscaling group'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#argument-reference


AWS AUTOSCALING POLICY
----------------------
➢ search 'aws autoscaling policy'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_policy#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_policy#argument-reference


AWS CLOUDWATCH METRIC ALARM
---------------------------
➢ search 'aws cloudwatch metric alarm'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_metric_alarm#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudwatch_metric_alarm#argument-reference




autoscaling.tf
--------------------------------------------------
#AutoScaling Launch Configuration
resource "aws_launch_configuration" "levelup-launchconfig" {	# launch configuration resource
  name_prefix     = "levelup-launchconfig"			# name prefix of all instances lauched by this config
  image_id        = lookup(var.AMIS, var.AWS_REGION)		# amazon machine image id and region
  instance_type   = "t2.micro"					# type hardware - t2.micro - free tier
  key_name        = aws_key_pair.levelup_key.key_name		# security key name
}

#Generate Key
resource "aws_key_pair" "levelup_key" {				# KeyPair
    key_name = "levelup_key"					# key name
    public_key = file(var.PATH_TO_PUBLIC_KEY)			# path to key file location
}

#Autoscaling Group
resource "aws_autoscaling_group" "levelup-autoscaling" {			# autoscaling group resource
  name                      = "levelup-autoscaling"				# autoscaling group name
  vpc_zone_identifier       = ["subnet-9e0ad9f5", "subnet-d7a6afad"]		# vpc zones - set craeted subnets
  launch_configuration      = aws_launch_configuration.levelup-launchconfig.name	# launch configuration
  min_size                  = 1							# minimum servers
  max_size                  = 2							# maximum servers
  health_check_grace_period = 200		# after 200s continuous checks failed, new instance will be created
  health_check_type         = "EC2"						# check type - EC2
  force_delete              = true						# delete if unhealthy

  tag {										# tag
    key                 = "Name"
    value               = "LevelUp Custom EC2 instance"
    propagate_at_launch = true
  }
}

#Autoscaling Configuration policy - Scaling Alarm				# Increasing policy
resource "aws_autoscaling_policy" "levelup-cpu-policy" {			# autoscaling policy resource
  name                   = "levelup-cpu-policy"					# autoscaling policy name
  autoscaling_group_name = aws_autoscaling_group.levelup-autoscaling.name	# linked autoscaling group
  adjustment_type        = "ChangeInCapacity"					# type adjustment
  scaling_adjustment     = "1"							# step of the adjustment
  cooldown               = "200"						# 200s update time period
  policy_type            = "SimpleScaling"					# type scaling
}

#Auto scaling Cloud Watch Monitoring						# Increasing alarm
resource "aws_cloudwatch_metric_alarm" "levelup-cpu-alarm" {			# cloud watch metric alarm resource
  alarm_name          = "levelup-cpu-alarm"					# alarm name
  alarm_description   = "Alarm once CPU Uses Increase"				# alarm descriptin
  comparison_operator = "GreaterThanOrEqualToThreshold"				# comparison operator
  evaluation_periods  = "2"							# evaluation period 2s
  metric_name         = "CPUUtilization"					# metric name
  namespace           = "AWS/EC2"						# namespace
  period              = "120"	# for 120s period will be monitor 2 evaluation and trigger on average 30% (treshold) deviation
  statistic           = "Average"						# statistic result
  threshold           = "30"							# treshold

  dimensions = {								# dimensions as autoscaling group
    "AutoScalingGroupName" = aws_autoscaling_group.levelup-autoscaling.name
  }

  actions_enabled = true							# enable action
  alarm_actions   = [aws_autoscaling_policy.levelup-cpu-policy.arn]		# alarm trigger cpu policy
}

#Auto Descaling Policy								# Decreasing policy
resource "aws_autoscaling_policy" "levelup-cpu-policy-scaledown" {		# autoscaling policy resource
  name                   = "levelup-cpu-policy-scaledown"			# autoscaling policy name
  autoscaling_group_name = aws_autoscaling_group.levelup-autoscaling.name	# linked autoscaling group
  adjustment_type        = "ChangeInCapacity"					# type adjustment
  scaling_adjustment     = "-1"							# step of the adjustment
  cooldown               = "200"						# 200s update time period
  policy_type            = "SimpleScaling"					# type scaling
}

#Auto descaling cloud watch 							# Decreasing alarm
resource "aws_cloudwatch_metric_alarm" "levelup-cpu-alarm-scaledown" {		# cloud watch metric alarm resource
  alarm_name          = "levelup-cpu-alarm-scaledown"				# alarm name
  alarm_description   = "Alarm once CPU Uses Decrease"				# alarm descriptin
  comparison_operator = "LessThanOrEqualToThreshold"				# comparison operator
  evaluation_periods  = "2"							# evaluation period 2s
  metric_name         = "CPUUtilization"					# metric name
  namespace           = "AWS/EC2"						# namespace
  period              = "120"	# for 120s period will be monitor 2 evaluation and trigger on average 10% (treshold) deviation
  statistic           = "Average"						# statistic result
  threshold           = "10"							# treshold

  dimensions = {								# dimensions as autoscaling group
    "AutoScalingGroupName" = aws_autoscaling_group.levelup-autoscaling.name
  }

  actions_enabled = true							# enable action
  alarm_actions   = [aws_autoscaling_policy.levelup-cpu-policy-scaledown.arn]	# alarm trigger cpu policy
}
--------------------------------------------------




provider.tf
--------------------------------------------------
provider "aws" {
  access_key = var.AWS_ACCESS_KEY
  secret_key = var.AWS_SECRET_KEY
  region     = var.AWS_REGION
}
--------------------------------------------------




variables.tf
--------------------------------------------------
variable "AWS_ACCESS_KEY" {
    type = string
    default = "AKIAY65Y5OPLU3XH5T6O"
}

variable "AWS_SECRET_KEY" {}

variable "AWS_REGION" {
default = "us-east-2"
}

variable "AMIS" {
    type = map
    default = {
        us-east-1 = "ami-0f40c8f97004632f9"
        us-east-2 = "ami-05692172625678b4e"
        us-west-2 = "ami-0352d5a37fb4f603f"
        us-west-1 = "ami-0f40c8f97004632f9"
    }
}

variable "PATH_TO_PRIVATE_KEY" {
  default = "levelup_key"
}

variable "PATH_TO_PUBLIC_KEY" {
  default = "levelup_key.pub"
}

variable "INSTANCE_USERNAME" {
  default = "ubuntu"
}
--------------------------------------------------




Login to the igitalOcean ubuntu and pull the files from github.
	terminal --> ssh root@IP
	terminal --> password

Update the linux package manager
	terminal --> sudo apt-get update

Pull the repo
	terminal --> git clone repo_url
	or
	terminal --> git pull

We need to install AWS CLI on the machine
	terminal --> sudo apt-get install awscli
	terminal --> y					# confirm


INIT
----
Initialize terrafomr
	terminal --> terraform init

Generate private and public key
	terminal --> ssh-keygen -f levelup_key
	terminal --> enter
	terminal --> enter

Verify key creation
	terminal --> ls
	# we should have 2 new files - levelup-key and levelup-key.pub

PLAN
----
Plan terraform resources
	terminal --> terraform plan
	terminal --> AWS Secret access key

	# the plan should be successful and we can review the logs
	# result: 	
		Plan: 7 to add, 0 to change, 0 to destroy.	

APPLY
-----
Apply the plan made on the DigitalOcean Ubuntu machine
	terminal --> terraform apply
	terminal --> xxxxxxxxxxxxxxxxxxxxxx		# provide the seucrity key
	terminal --> yes				# confirm

Check resources creation on AWS/EC2.
We can check autoscaling groups on AWS/EC2/Auto Scaling Groups
	- we can see the policies
	- activity, instance management, monitoring and more
We can see cloud watch on AWS Management Console/CloudWatch
	- go to Alarms - We have 2 alarms
		- OK - increase scaling - no load or increased traffic
		- NOK - decreased scaling - the load is below 10%, but the minimum count servers requirement is allready satified

We will simulate increased load on the instance to trigger the upscaling policy.

We can connect the AWS instance from local PC/box.
Copy the public IP from the console
	terminal --> ssh instance_public_ip -l ubuntu -i levelup_key

	# ssh instance_public_ip		- connect to the instance
	# -l ubuntu				- login as ubuntu user
	# -i levelup_key			- use terraform public key

Now we are logged into the instance.

Switch to root user
	instance terminal --> sudo -s

Update the instance package manager
	instance terminal --> apt-get update

Install stress test
	instance terminal --> apt-get install stress

Start stress test fo increase the load i=on the instance
	instance terminal --> stress --cpu 2 --timeout 300

	# stress			- common stress command
	# --cpu 2			- cpu number
	# --timeout 300			- period in seconds - 300s = 5 minutes

Go to the AWS/CloudWatch and check the graphs. Both alarms are OK. 
Few minutes later we have NOK alarm for increased load and new instance is created on AWS/EC2.
We can check the events on AWS/EC2/Auto Scaling Groups/Activities

After end of the 5 minutes stress on the instance descaling alarm will trigger decreasing policy and the second instance on AWS/EC2 will be terminated.
We can monitor the events on AWS/EC2/Auto Scaling Groups/Activities.

Exit the AWS instance
	instance terminal --> exit


DESTROY
-------
We can now destroy the created resources on AWS
	terminal --> terraform destroy
	terminal --> xxxxxxxxxxxxxxxxxxxxxx	# provide the seucrity key
	terminal --> yes






54. Your Reviews are Important!
===============================

Your reviews are very important to me! That's the single most motivating factor for me to keep going. So please consider leaving a few lines when writing a review:

I always aim for a 5-star course. If you don't think the course is 5 stars, please write to me at anshulc55@gmail.com about what you think is missing and how I can improve.


If you have already reviewed the course and want to change your review, it's quite simple-

You can change your course review from the course player by:

1. Click the three dots at the top right-hand corner of the page.

2. Next, click Edit your rating.

3. Make the changes, and click Save and Exit to finalize your edits.





55. Load Balancing in AWS
=========================

➢ Amazon AWS Elastic Load Balancer is a purpose built service for distributing workloads.
	- load balancer will distribute the traffic across all available instances

➢ For ELB, User must specify One Public Subnet for at least two availability zones.
	- at least one public subnet and two availability zones for load balancing

➢ Accept incoming traffic from client and route to Target.

➢ Monitor Health of registered target and send traffic to only healthy Targets.
	- as soon as health check start fail, AWS will mark the isntance as unhealthy and load balancer will NOT send traffic 

➢ Deleting ELB won’t delete the targets associated to it.
	- if we delete the load balancer, the instances will NOT be deleted - no cascate deletion.
	- we need to provide a confirmation before deleting a load balancer (ELB by default prevented = true - option)

➢ Supports SSL offloading which allow ELB to bypass SSL termination by removing SSL based encryption.
	- load balancer decript traffic and then send it to the instances
	- load balancer encript traffic when sending to the user (external target)


		Clients				Elastic Load Balancer				EC2 IKnstances

												-----------------
							----------------------------------------|  Instance 1	|
							|					|		|
	Tablet-------------------		-----------------				-----------------
				|		|		|				-----------------
	Mobile--------------------------------->| Balancer	|-------------------------------|  Instance 2	|
				|		|		|				|		|
	PC-----------------------		-----------------				-----------------
							|						.
							|						.
							|						.
							|						.
							|					-----------------
							----------------------------------------|  Instance N	|
												|		|
												-----------------

If all instances are healty, the load balancer will route traffic across all instances. The load balancer will not route traffic to unhealthy instances.




Types of AWS Elastic Load Balancers
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

➢ Classic Load Balancer

➢ Network Load Balancer

➢ Application Load Balancer





Classic Load Balancer - Used for EC2 Classic Instances only (one way traffic only - NOT RECOMMENDED)
--------------------- 
	➢ This is the previous generation’s load balancer and also it doesn’t allow host-based or path based routing.
		- NOT RECOMMENDED

	➢ Routing decisions can be taken in transport layer (TCP/SSL) or the application layer (HTTP/HTTPS).

	➢ Classic Load Balancers require a fixed connection between the load balancer port and container instance port.
		- NOT RECOMMENDED



Network Load Balancer - Works at Forth Layer of OSI, it uses TCP and UDP connections only. (CANNOT be used for HTTP & HTTPS)
---------------------
	➢ It can handle millions of requests per second.
		
	➢ Support the Static IP address for Load Balancer.

	➢ It supports routing request to multiple applications on single EC2 Instance.
		- all different applications must listen on different ports

						
		availability zone		|		availability zone	
			A			|			B
		-----------------		v		-----------------
	VPC	|		|	-----------------	|		|
	--------------------------------|   Balancer	|--------------------------------
	|	| -------------	|	|		|	| -------------	|	|
	|	| |	      | |	-----------------	| |           |	|	|
	|	| |	      | |		|		| |           |	|	|
	|	| | Instances |<|-------------------------------|>| Instances | |	|
	|	| |	      | |				| |           | |	|
	|	| |	      | |				| |           |	|	|
	|	| -------------	|				| -------------	|	|
	|	|		|				|		|	|
	---------------------------------------------------------------------------------
		|		|				|		|
		-----------------				-----------------



Application Load Balancer - Application Load Balancer in AWS makes routing decisions at the application layer (HTTP/ HTTPs) of the 
-------------------------   OSI model. - MOST ADVANCED LOAD BALANCER - RECOMMENDED

➢ ALB supports path-based and host-based routing.		
	➢ path based routing example: 
		- when we open yahoo.com and open one of the subpages the path is changed to yahoo.com/some_page

	➢ host-based routing example:
		- here we can have multiple instances for one url
			- few instances for home page
			- few instances for my card etc.
		
➢ Cross-Zone load balancing is enabled.



		availability zone		|		availability zone	
			A			|			B
		-----------------		v		-----------------
	VPC	|		|	-----------------	|		|
	--------------------------------|   Balancer	|--------------------------------
	|	| -------------	|	|		|	| -------------	|	|
	|	| | Path 1    |<|---	-----------------   ----|>| Path 2    |	|	|
	|	| |	      | |  |		|	    |	| |           |	|	|
	|	| |Instance 1 |<|-------------------------------|>|Instance 2 | |	|
	|	| |           | |  |			    |	| |           | |	|
	|	| | App 1     |<|---			    ----|>| App 2     |	|	|
	|	| -------------	|				| -------------	|	|
	|	|		|				|		|	|
	---------------------------------------------------------------------------------
		|		|				|		|
		-----------------				-----------------


We can assign specific hardware to specific path only - specific load preferences.




56. Lab : AWS Load Balancing
============================

We have 5 files
---------------
➢ autoscaling.tf
➢ elb.tf
➢ prvider.tf
➢ variables.tf
➢ vpc.tf

It si a good practice to keep all similar resources in separate files
	- all Security Groups should be in security_groups.tf
	- all ELB configs should be in elb.tf
	- etc.

For this example we are mixing different resources in one file.



AWS LAUNCH CONFIGURATION
------------------------
➢ search 'aws launch configuration'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/launch_configuration#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/launch_configuration#argument-reference


AWS AUTOSCALING GROUP
---------------------
➢ search 'aws autoscaling group'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#argument-reference


autoscaling.tf
--------------------------------------------------
#AutoScaling Launch Configuration
resource "aws_launch_configuration" "levelup-launchconfig" {		# aws lounch configuration resource
  name_prefix     = "levelup-launchconfig"				# launch configuration name
  image_id        = lookup(var.AMIS, var.AWS_REGION)			# AIM ID (amazon machine image) and region
  instance_type   = "t2.micro"						# type hardware - t2.micro free tier
  key_name        = aws_key_pair.levelup_key.key_name			# secret key name
  security_groups = [aws_security_group.levelup-instance.id]		# sec group id
  user_data       = "#!/bin/bash\napt-get update\napt-get -y install net-tools nginx\nMYIP=`ifconfig | grep -E '(inet 10)|(addr:10)' | awk '{ print $2 }' | cut -d ':' -f2`\necho 'Hello Team\nThis is my IP: '$MYIP > /var/www/html/index.html"

  lifecycle {
    create_before_destroy = true	# first destroy existing instance if creating a new one
  }
}

#Generate Key
resource "aws_key_pair" "levelup_key" {				# sec key resoource
    key_name = "levelup_key"					# key name
    public_key = file(var.PATH_TO_PUBLIC_KEY)			# path to public sec key location
}

#Autoscaling Group
resource "aws_autoscaling_group" "levelup-autoscaling" {		# aws autoscaling group resource
  name                      = "levelup-autoscaling"			# autoscaling group name
  vpc_zone_identifier       = [aws_subnet.levelupvpc-public-1.id, aws_subnet.levelupvpc-public-2.id]	# public subnet 1 & 2 ids 
  launch_configuration      = aws_launch_configuration.levelup-launchconfig.name	# launch configuration name
  min_size                  = 2								# min count instances
  max_size                  = 2								# max count instances
  health_check_grace_period = 200		# after 200s continuous checks failed, new instance will be created
  health_check_type         = "ELB"				# health check will be perormed by ELB
  load_balancers            = [aws_elb.levelup-elb.name]				# used load balancer name
  force_delete              = true							# delete instance if not healthy

  tag {
    key                 = "Name"
    value               = "LevelUp Custom EC2 instance via LB"
    propagate_at_launch = true
  }
}

output "ELB" {							# print dns name of the load balancer on launch
  value = aws_elb.levelup-elb.dns_name
}
--------------------------------------------------



AWS LOAD BALANCER
-----------------
➢ search 'aws elb'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elb#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/elb#argument-reference

AWS SECURITY GROUP
------------------
We can see all parameters and syntax for the VPC - https://registry.terraform.io/providers/hashicorp/aws/latest/docs
➢ search 'aws security group'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group#argument-reference


elb.tf
--------------------------------------------------
#AWS ELB Configuration
resource "aws_elb" "levelup-elb" {			# load balancer resource
  name            = "levelup-elb"								# load balancer name
  subnets         = [aws_subnet.levelupvpc-public-1.id, aws_subnet.levelupvpc-public-2.id]	# 2 public subnets ids
  security_groups = [aws_security_group.levelup-elb-securitygroup.id]				# sec group id
  
  listener {				# set listener for incoming requests
    instance_port     = 80		# instance will listen to port 80
    instance_protocol = "http"		# with protocol http
    lb_port           = 80		# balancer will listen to port 80
    lb_protocol       = "http"		# with protocol http
  }

  health_check {			# health check configs
    healthy_threshold   = 2		# will mark instance healthy after 2 consecutive success health checks
    unhealthy_threshold = 2		# will mark instance unhealthy after 2 consecutive fail health checks
    timeout             = 3		# timeout 3s
    target              = "HTTP:80/"
    interval            = 30		# after 30s this check will be triggered on port 80 with HTTP
  }	

  cross_zone_load_balancing   = true	# allow balancing across different availability zones
  connection_draining         = true	# Allows the ELB to complete active requests to an instance before removing it from
					# service (e.g., during scaling-in, deployments, or unhealthy instances).
					# Prevents abrupt termination of user sessions.
					# How draining works - When enabled, the ELB stops sending new requests to a deregistered 
					# instance but allows existing requests to complete.
					# If requests exceed the connection_draining_timeout, they are forcibly closed.

  connection_draining_timeout = 400	# perform connection draining for 400s

  tags = {				# tag elb
    Name = "levelup-elb"
  }
}

#Security group for AWS ELB
resource "aws_security_group" "levelup-elb-securitygroup" {	# SG resource for load balancer
  vpc_id      = aws_vpc.levelupvpc.id				# vpc id
  name        = "levelup-elb-sg"				# SG name
  description = "security group for Elastic Load Balancer"	# short description
  
  egress {				# load balancer outbound traffic
    from_port   = 0			# from all ports - no restrictions
    to_port     = 0			# to all ports - no restrictions
    protocol    = "-1"			# '-1' all protocols - no restrictions - recommended for egress traffic
    cidr_blocks = ["0.0.0.0/0"]		# IP range - public connection
  }

  ingress {				# load balancer inbound traffic
    from_port   = 80			# from port 80 
    to_port     = 80			# to port 80
    protocol    = "tcp"			# TCP protocol only
    cidr_blocks = ["0.0.0.0/0"]		# no restriction - public accessable
  }

  tags = {
    Name = "levelup-elb-sg"
  }
}

#Security group for the Instances
resource "aws_security_group" "levelup-instance" {		# SG resource
  vpc_id      = aws_vpc.levelupvpc.id				# vpc id
  name        = "levelup-instance"				# SG name
  description = "security group for instances"			# shoet description
  
  egress {				# instance outbound traffic rule
    from_port   = 0			# from all ports
    to_port     = 0			# to all ports
    protocol    = "-1"			# '-1' - allow all protocols 
    cidr_blocks = ["0.0.0.0/0"]		# IP range - not restricted
  }

  ingress {				# instance ingress traffic rule
    from_port   = 22			# from port 22 only
    to_port     = 22			# to port 22 only
    protocol    = "tcp"			# TCP protocol only
    cidr_blocks = ["0.0.0.0/0"]		# IP range - not restricted - not recommended - (recommended to specify ELB IP)
  }

  ingress {				# second instance inbound traffic rule for the load balancer
    from_port       = 80		# from port 80
    to_port         = 80		# to port 80
    protocol        = "tcp"		# TCP protocol only
    security_groups = [aws_security_group.levelup-elb-securitygroup.id]	 # ELB SG id 
  }	# only the load balancer can make connection on port 80 with the instance

  tags = {
    Name = "levelup-instance"
  }
}
--------------------------------------------------


prvider.tf
--------------------------------------------------
provider "aws" {
  access_key = var.AWS_ACCESS_KEY
  secret_key = var.AWS_SECRET_KEY
  region     = var.AWS_REGION
}
--------------------------------------------------


variables.tf
--------------------------------------------------
variable "AWS_ACCESS_KEY" {
    type = string
    default = "AKIAY65Y5OPLU3XH5T6O"
}

variable "AWS_SECRET_KEY" {}

variable "AWS_REGION" {
default = "us-east-2"
}

variable "AMIS" {
    type = map
    default = {
        us-east-1 = "ami-0f40c8f97004632f9"
        us-east-2 = "ami-05692172625678b4e"
        us-west-2 = "ami-0352d5a37fb4f603f"
        us-west-1 = "ami-0f40c8f97004632f9"
    }
}

variable "PATH_TO_PRIVATE_KEY" {
  default = "levelup_key"
}

variable "PATH_TO_PUBLIC_KEY" {
  default = "levelup_key.pub"
}

variable "INSTANCE_USERNAME" {
  default = "ubuntu"
}
--------------------------------------------------



AWS VPC
-------
➢ search 'aws vpc' in the search bar on left and choose 'aws_vpc'
   ➢ Example usage and syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc#example-usage
   ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc#argument-reference

AWS SUBNET
----------
➢ search 'aws subnet'
   ➢ Example usage and syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet#example-usage
   ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/subnet#argument-reference

AWS INTERNET GATEWAY
--------------------
➢ search 'aws internet gateway'
  ➢ Example syntax - ttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway#argument-reference

AWS ROUTE TABLE
---------------
➢ search 'aws route table'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table#argument-reference

AWS ROUTE TABLE ASSOCIATION
---------------------------
➢ search 'aws route table assocation'
  ➢ Example syntax - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association#example-usage
  ➢ Arguments references - https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/route_table_association#argument-reference



vpc.tf
--------------------------------------------------
#Create AWS VPC
resource "aws_vpc" "levelupvpc" {
  cidr_block       = "10.0.0.0/16"	# Classless Inter-Domain Routing (CIDR) block
  instance_tenancy = "default"		# more than one instance can run on the same hardware - preffered - minimized consts
  enable_dns_support   = "true"
  enable_dns_hostnames = "true"	  # create hostname and dns of our instance name, the name of our aws instance will work as dns

  tags = {
    Name = "levelupvpc"
  }
}

# Public Subnets in Custom VPC
resource "aws_subnet" "levelupvpc-public-1" {		# first public subnet resource
  vpc_id                  = aws_vpc.levelupvpc.id	# ID of our VPC
  cidr_block              = "10.0.1.0/24"		# IP range - we can't overlap with other subnets IP ranges
  map_public_ip_on_launch = "true"	    	# on launch the public IP will be asociated with this instance - public subnet
  availability_zone       = "us-east-2a"	# first availability zone for public subnet

  tags = {					# tag
    Name = "levelupvpc-public-1"
  }
}

resource "aws_subnet" "levelupvpc-public-2" {
  vpc_id                  = aws_vpc.levelupvpc.id
  cidr_block              = "10.0.2.0/24"
  map_public_ip_on_launch = "true"
  availability_zone       = "us-east-2b"

  tags = {
    Name = "levelupvpc-public-2"
  }
}

resource "aws_subnet" "levelupvpc-public-3" {
  vpc_id                  = aws_vpc.levelupvpc.id
  cidr_block              = "10.0.3.0/24"
  map_public_ip_on_launch = "true"
  availability_zone       = "us-east-2c"

  tags = {
    Name = "levelupvpc-public-3"
  }
}

# Private Subnets in Custom VPC
resource "aws_subnet" "levelupvpc-private-1" {
  vpc_id                  = aws_vpc.levelupvpc.id
  cidr_block              = "10.0.4.0/24"
  map_public_ip_on_launch = "false"
  availability_zone       = "us-east-2a"

  tags = {
    Name = "levelupvpc-private-1"
  }
}

resource "aws_subnet" "levelupvpc-private-2" {
  vpc_id                  = aws_vpc.levelupvpc.id
  cidr_block              = "10.0.5.0/24"
  map_public_ip_on_launch = "false"
  availability_zone       = "us-east-2b"

  tags = {
    Name = "levelupvpc-private-2"
  }
}

resource "aws_subnet" "levelupvpc-private-3" {
  vpc_id                  = aws_vpc.levelupvpc.id
  cidr_block              = "10.0.6.0/24"
  map_public_ip_on_launch = "false"
  availability_zone       = "us-east-2c"

  tags = {
    Name = "levelupvpc-private-3"
  }
}

# Custom internet Gateway
resource "aws_internet_gateway" "levelup-gw" {
  vpc_id = aws_vpc.levelupvpc.id

  tags = {
    Name = "levelup-gw"
  }
}

#Routing Table for the Custom VPC
resource "aws_route_table" "levelup-public" {
  vpc_id = aws_vpc.levelupvpc.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.levelup-gw.id
  }

  tags = {
    Name = "levelup-public-1"
  }
}

resource "aws_route_table_association" "levelup-public-1-a" {
  subnet_id      = aws_subnet.levelupvpc-public-1.id
  route_table_id = aws_route_table.levelup-public.id
}

resource "aws_route_table_association" "levelup-public-2-a" {
  subnet_id      = aws_subnet.levelupvpc-public-2.id
  route_table_id = aws_route_table.levelup-public.id
}

resource "aws_route_table_association" "levelup-public-3-a" {
  subnet_id      = aws_subnet.levelupvpc-public-3.id
  route_table_id = aws_route_table.levelup-public.id
}
--------------------------------------------------


Login to the igitalOcean ubuntu and pull the files from github.
	terminal --> ssh root@IP
	terminal --> password

Update the linux package manager
	terminal --> sudo apt-get update

Pull the repo
	terminal --> git clone repo_url
	or
	terminal --> git pull

We need to install AWS CLI on the machine
	terminal --> sudo apt-get install awscli
	terminal --> y					# confirm


INIT
----
Initialize terrafomr
	terminal --> terraform init

Generate private and public key
	terminal --> ssh-keygen -f levelup_key
	terminal --> enter
	terminal --> enter

Verify key creation
	terminal --> ls
	# we should have 2 new files - levelup-key and levelup-key.pub

PLAN
----
Plan terraform resources
	terminal --> terraform plan
	terminal --> AWS Secret access key

	# the plan should be successful and we can review the logs
	# result: 	
		Plan: 18 to add, 0 to change, 0 to destroy.

		Changes to Outputs:
		  + ELB = (known after apply)	

APPLY
-----
Apply the plan made on the DigitalOcean Ubuntu machine
	terminal --> terraform apply
	terminal --> xxxxxxxxxxxxxxxxxxxxxx		# provide the seucrity key
	terminal --> yes				# confirm

We wait until all resources are created. When created we can see the ELB endpoint printed on the console (dns address).
Wait a little bit more for nginx service to start and send request to the load balancer.

Send request to the ELB
	terminal --> curl levelup-elb-1784717867.us-east-2.elb.amazon.com 

	# we should receive the message we set in the autoscale.tf/"aws_launch_configuration"/user_data param
	# result:
		Hello Team
		This is my IP: 10.0.2.10

Send request to the ELB again
	terminal --> curl levelup-elb-1784717867.us-east-2.elb.amazon.com 

	# we should recieve the same message but with different IP. 
	# this mean that the load balancer route the traffic to the second instance
	# result 
		Hello Team
		This is my IP: 10.0.1.110

We can send request to the same address from our local PC via browser. The result should be the same.

Check resources creation on AWS/EC2.
We can check the ELB on AWS/Load Balancers
	- We can manually remove instances from the load balancer and they will NOT be recreated.


DESTROY
-------
We can now destroy the created resources on AWS
	terminal --> terraform destroy
	terminal --> xxxxxxxxxxxxxxxxxxxxxx	# provide the seucrity key
	terminal --> yes












